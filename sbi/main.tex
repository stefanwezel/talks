\documentclass[12pt]{article}

% Some typesetting decisions
\usepackage[utf8]{inputenc}

% Typesetting and basic formatting. 
% This PDF is made to be read on-screen,
% so we use large fonts and little margin
\usepackage[margin=30mm]{geometry}
\usepackage{fourier}
\usepackage{setspace}
\usepackage{graphicx}
\usepackage{algorithm2e}
\setstretch{1.1}
\setlength{\parindent}{0pt}
\setlength{\parskip}{12pt}
\frenchspacing
\sloppy


% Links
\usepackage{xcolor}
\usepackage{hyperref}
\hypersetup{colorlinks,linkcolor={green!50!black},citecolor={blue!50!black}, urlcolor={red!50!black}}  
% This one is for demo-purposes only, don't use it in your submission ;) 
\usepackage{blindtext}

% Citation with natbib: 
% Use \citet{} and \citep{} only, not \cite{}
\usepackage{natbib}
\bibliographystyle{abbrvnat}



% Custom (maths) commands
\usepackage{amsmath, amssymb}
\usepackage{bm}

\newcommand{\Ebb}{\mathbb{E}}
\newcommand{\Rbb}{\mathbb{R}}
\newcommand{\Sbb}{{\mathbb{S}}}
\newcommand{\Tbb}{\mathbb{T}}
\newcommand{\Nbb}{\mathbb{N}}
\newcommand{\Xbb}{{\mathbb{X}}}
\newcommand{\Pbb}{\mathbb{P}}
\newcommand{\Dbb}{\mathbb{D}}
\newcommand{\Ybb}{\mathbb{Y}}
\newcommand{\onebb}{\mathbb{1}}
\newcommand{\Ncal}{\mathcal{N}}
\newcommand{\Mcal}{\mathcal{M}}
\newcommand{\Lcal}{\mathcal{L}}
\newcommand{\Bcal}{\mathcal{B}} 
\newcommand{\Qcal}{\mathcal{Q}} 
\newcommand{\Acal}{\mathcal{A}}
\newcommand{\Xcal}{\mathcal{X}}
\newcommand{\Tcal}{\mathcal{T}}
\newcommand{\Pcal}{\mathcal{P}}
\newcommand{\Zcal}{\mathcal{Z}}
\newcommand{\Rcal}{\mathcal{R}}
\newcommand{\Ocal}{\mathcal{O}}
\newcommand{\Fcal}{\mathcal{F}}
\newcommand{\Dcal}{\mathcal{D}}
\newcommand{\Ycal}{\mathcal{Y}}
\newcommand{\Ecal}{\mathcal{E}}
\newcommand{\Hcal}{\mathcal{H}}
\newcommand{\Ucal}{\mathcal{U}}
\newcommand{\Ccal}{\mathcal{C}}
\newcommand{\Ical}{\mathcal{I}}
\newcommand{\diff}{\,\text{d}}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\cond}{cond}
\DeclareMathOperator{\gp}{GP}
\DeclareMathOperator{\divergence}{div}
\DeclareMathOperator{\curl}{curl}
\DeclareMathOperator{\supp}{supp}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}






% Insert the title of your presentation, your name, and your e-mail here.
% Leave the rest as is.
\title{\vskip-3em \bf 
	Simulation-based Inference
    }
\author{
    A Summary Written by Stefan Wezel \\
    \texttt{stefan.wezel@student.uni-tuebingen.de}
}
\date{\it Machine Learning for and with Dynamical Systems\\Summer Term 2021}


\begin{document}

\maketitle

\begin{abstract}\vskip-1.5em \noindent
Simulators are used across different scientific domains where they serve as valuable tools to encode empirical knowledge about a system of interest. Inference in this setting often means finding parameters of the simulator for a given, real-world observation, which typically cannot be computed analytically.\citet{papamakarios2016fast} and \citet{lueckmann2017flexible} propose to learn a posterior over a simulators parameters by using neural density estimators. Here, we give an overview of their work and SBI in general.
\end{abstract}


\section*{Problem Setting and Related Work}
Scientific fields, such as population genetics, particle physics, epidemiology, astrophysics among others make use of sophisticated simulators to model observed systems \citep{brehmer2020simulation, de2020simulation, delaunoy2020lightning,cranmer2020frontier, pritchard1999population}. These simulators serve as forward models with strong inductive biases, encoding prior knowledge. Performing inference in this setting, however, would require a finding a posterior over parameters $\theta$ for a given observation $x_0$. This can be stated in closed form as 
\begin{align}
	p(\theta\mid x=x_0) = \frac{p(x\mid \theta)p(\theta)}{p(x)} = \frac{\overbrace{\int p(x,z\mid \theta)\diff z}^{\text{intractable}} p(\theta)}{\int p(x\mid \theta)p(\theta) \diff \theta},
\end{align}
where $z$ is a nuisance parameter and $x$ is observation data from experiments or simulations. If likelihood and evidence are intractable, which is typically the case, this cannot be computed analytically.\\
A collective term for methods that aim to solve this inverse problem is Approximate Bayesian Computation (ABC). The most simple approach is rejection ABC \citep{pritchard1999population} where samples produced by a simulator are discarded if not within an $\epsilon$-ball around an observation of interest. For small values of $\epsilon$ this method may take unfeasibly many steps to even produce a single observation. For large $\epsilon$ it is not precise. Moreover, this method does not produce a full posterior over the parameter but merely yields point estimates that can be used to approximate a posterior. However, this approximated posterior $\hat{p}(\theta\mid  \mid\mid x-x_0 \mid\mid < \epsilon)$ is not conditioned on an actual observation but rather on a value $\epsilon$-close to it.\\
With Sampling ABC \citep{marjoram2003markov} and Sequential ABC \citep{beaumont2009adaptive,bonassi2015sequential} improvements over rejection ABC have been proposed. These methods produce samples more efficiently. While this can lead to faster convergence, they also do not produce a full posterior over parameters and thus suffer from the latter problem as well.
 



\section*{Neural Approach}
\begin{figure}
	\centering
	\includegraphics[width=.9\linewidth]{figures/sbi0.pdf}
	\caption{Given samples by the simulator, Multilayer perceptrons (MLP) are trained to parameterize a distribution over parameters generating the sample. A training signal is created by sampling from this distribution and comparing the sample to the actual parameters which are known.}
	\label{fig:sbiloop}
\end{figure} 
\citet{papamakarios2016fast} build on recent advances in deep learning and propose to learn a posterior over parameters directly from samples produced by a simulator. They parameterize a Gaussian Mixture Model (GMM) with a Deep Neural Network (DNN) with parameters. They use the simulator to perform $n$ simulations and store pairs of observations $x_i$ and corresponding parameters $\theta_i$, sampled from a proposal prior $\tilde{p}(\theta) = p(\theta)$, where $p(\theta)$ is a uniform or Gaussian distribution. This gives the set $\lbrace(x_i,\theta_i)\rbrace_{i \in n}$ which \citet{papamakarios2016fast} use as training data. A DNN with parameters $\phi$ is fitted to parameterize a GMM
\begin{align}
	q_{\phi}(\theta\mid x) = \sum_k \alpha_k \mathcal{N}(\theta\mid m_k, S_k) = \sum_k \phi_1(x)_k \mathcal{N}(\theta\mid \phi_2(x)_k, diag(\phi_3(x))_k)
\end{align}
, where $k$ is the number of components, $m$ the mean and $S$ the covariance matrix of a Gaussian, and $\phi_{\lbrace 1,2,3 \rbrace}$ are distinct (but not necessarily mutually exclusive) subsets of a DNN.\\
To find a suiting function $\phi$, $x_{0,...,n}$ are passed to it. Each respective output is used to parameterize $q_{\phi}(\theta\mid x)$. A sample $\hat{\theta}$ is then drawn from $\frac{p(\theta)}{\tilde{p}(\theta)} q(\theta\mid x)$. The difference between this sample $\hat{\theta}$ and the actual $\theta$ forms a loss which is backpropagated through $\phi$. This completes an 'inner' training loop. \citet{papamakarios2016fast} further propose an 'outer' training loop, where once $\phi$ is fitted to $n$ observations, $\frac{p(\theta)}{\tilde{p}(\theta)}q(\theta \mid  x=x_0)$ replaces the proposal prior for a specific observation of interest. This procedure is summarized in Algorithm~\ref{alg:prior}. This, however, requires $\tilde{p}(\theta)$ to be of a form so that the importance weights $\frac{p(\theta)}{\tilde{p}(\theta)}$ can be computed analytically.





\begin{algorithm}[H]
	\caption{Training loop proposed by \citet{papamakarios2016fast}.}
	%	\tcp{Initial proposal prior}
	$\tilde{p}(\theta) \leftarrow p(\theta)$\\
	%	\tcp{Create training set}
	\Repeat{$\tilde{p}(\theta)$ has converged}{
		\For{$n=1..N$}{
			sample $\theta_n \sim \tilde{p}(\theta)$ \\
			sample $x_n \sim p(x\mid \theta_n)$ \\
		}
		train $q_{\phi}(\theta\mid x)$ on $\lbrace x_n, \theta_n \rbrace$\\
		%		\color{orange}$\hat{p}(\theta\mid x=x_0) \leftarrow \frac{p(\theta)}{\tilde{p}(c)}q_{\phi}(\theta\mid  x)$
		$\tilde{p}(\theta) \leftarrow \frac{p(\theta)}{\tilde{p}(\theta)}q_{\phi}(\theta\mid x)$}
	\label{alg:prior}
\end{algorithm}




\section*{Application in Neuroscience}
\citet{lueckmann2017flexible} propose further enhancements to \citet{papamakarios2016fast}. They apply SBI to forward models widely used in neuro-science, such as the Hodgkin-Huxley model \cite{hodgkin1952quantitative}. They state that simulators used in this field often produce nonsensical observations. To alleviate this, \citet{lueckmann2017flexible} additionally train a classifier that learns to detect parameter sets that will produce such 'bad' simulations, which are then discarded.\\
Further, they state that finding useful summary statistics of the often high-dimensional data is challenging. By using a  recurrent neural network to extract features from observations, they find an informative, learned summary statistic.\\
Moreover, \citet{lueckmann2017flexible} formulate a loss such that it includes the importance weighting. This allows the use of more complex proposal priors, as they don't need to be computed analytically in their method.\\
\citet{lueckmann2017flexible} evaluate their method for different models and find that it reliably finds matching parameter settings for synthetic data. On in-vitro experiments they find parameter settings that match empirical data accurately.







\section*{Conclusion}




Simulators are an important tool of reasarch scientiest across domains. SBI enables researches to leverage these inductive biases and perform inference with them.. \citet{papamakarios2016fast} build on recent advances in deep learning and propose a flexible and powerful SBI framework. \citet{lueckmann2017flexible} apply their method to a neuro-science setting and alleviate some encountered shortcomings by introducing further enhancements. An afterthought of our summary is that SBI methods can be applied in different settings where simulators are used but is not necessarily a fit-all solution. However, adaptions can be made accordingly, to suit a given task.





\bibliography{references}
\end{document}