\documentclass[12pt]{article}

% Some typesetting decisions
\usepackage[utf8]{inputenc}

% Typesetting and basic formatting. 
% This PDF is made to be read on-screen,
% so we use large fonts and little margin
\usepackage[margin=30mm]{geometry}
\usepackage{fourier}
\usepackage{setspace}
\usepackage{graphicx}
\usepackage{algorithm2e}
\setstretch{1.1}
\setlength{\parindent}{0pt}
\setlength{\parskip}{12pt}
\frenchspacing
\sloppy


% Links
\usepackage{xcolor}
\usepackage{hyperref}
\hypersetup{colorlinks,linkcolor={green!50!black},citecolor={blue!50!black}, urlcolor={red!50!black}}  
% This one is for demo-purposes only, don't use it in your submission ;) 
\usepackage{blindtext}

% Citation with natbib: 
% Use \citet{} and \citep{} only, not \cite{}
\usepackage{natbib}
\bibliographystyle{abbrvnat}



% Custom (maths) commands
\usepackage{amsmath, amssymb}
\usepackage{bm}

\newcommand{\Ebb}{\mathbb{E}}
\newcommand{\Rbb}{\mathbb{R}}
\newcommand{\Sbb}{{\mathbb{S}}}
\newcommand{\Tbb}{\mathbb{T}}
\newcommand{\Nbb}{\mathbb{N}}
\newcommand{\Xbb}{{\mathbb{X}}}
\newcommand{\Pbb}{\mathbb{P}}
\newcommand{\Dbb}{\mathbb{D}}
\newcommand{\Ybb}{\mathbb{Y}}
\newcommand{\onebb}{\mathbb{1}}
\newcommand{\Ncal}{\mathcal{N}}
\newcommand{\Mcal}{\mathcal{M}}
\newcommand{\Lcal}{\mathcal{L}}
\newcommand{\Bcal}{\mathcal{B}} 
\newcommand{\Qcal}{\mathcal{Q}} 
\newcommand{\Acal}{\mathcal{A}}
\newcommand{\Xcal}{\mathcal{X}}
\newcommand{\Tcal}{\mathcal{T}}
\newcommand{\Pcal}{\mathcal{P}}
\newcommand{\Zcal}{\mathcal{Z}}
\newcommand{\Rcal}{\mathcal{R}}
\newcommand{\Ocal}{\mathcal{O}}
\newcommand{\Fcal}{\mathcal{F}}
\newcommand{\Dcal}{\mathcal{D}}
\newcommand{\Ycal}{\mathcal{Y}}
\newcommand{\Ecal}{\mathcal{E}}
\newcommand{\Hcal}{\mathcal{H}}
\newcommand{\Ucal}{\mathcal{U}}
\newcommand{\Ccal}{\mathcal{C}}
\newcommand{\Ical}{\mathcal{I}}
\newcommand{\diff}{\,\text{d}}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\cond}{cond}
\DeclareMathOperator{\gp}{GP}
\DeclareMathOperator{\divergence}{div}
\DeclareMathOperator{\curl}{curl}
\DeclareMathOperator{\supp}{supp}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}






% Insert the title of your presentation, your name, and your e-mail here.
% Leave the rest as is.
\title{\vskip-3em \bf 
	Simulation-based Inference
    }
\author{
    A Summary Written by Stefan Wezel \\
    \texttt{stefan.wezel@student.uni-tuebingen.de}
}
\date{\it Machine Learning for and with Dynamical Systems\\Summer Term 2021}


\begin{document}

\maketitle

\begin{abstract}\vskip-1.5em \noindent
Simulators are used across different scientific domains where they serve as valuable tools to encode empirical knowledge about a system of interest. Inference in this setting often means finding parameters of the simulator for a given, real-world observation, which typically cannot be computed analytically.\citet{papamakarios2016fast} and \citet{lueckmann2017flexible} propose to learn a posterior over a simulators parameters by using Bayesian neural density estimators. Here, we give an overview of their work and SBI in general.
\end{abstract}


\section*{Problem Setting and Related Work}
Scientific fields, such as population genetics, particle physics, epidemiology, astrophysics among others make use of sophisticated simulators to model observed systems \citep{brehmer2020simulation, de2020simulation, delaunoy2020lightning,cranmer2020frontier, pritchard1999population}. These simulators serve as forward models with strong inductive biases, encoding prior knowledge. Performing inference in this setting, however, would require a finding a posterior over parameters $\theta$ for a given observation $x_0$. This can be stated in closed form as 
\begin{align}
	p(\theta\mid x=x_0) = \frac{p(x\mid \theta)p(\theta)}{p(x)} = \frac{\overbrace{\int p(x,z\mid \theta)\diff z}^{\text{intractable}} p(\theta)}{\int p(x\mid \theta)p(\theta) \diff \theta},
\end{align}
where $z$ is a nuisance parameter and $x$ is observation data from experiments or simulations. This term typically cannot be computed analytically.\\
A collective term for methods that aim to solve this inverse problem is Approximate Bayesian Computation (ABC). The most simple approach is rejection ABC \citep{pritchard1999population} where samples produced by a simulator are discarded if not within an $\epsilon$-ball around an observation $x_0$. For small values of $\epsilon$ this method is inefficient. For large $\epsilon$ it is not precise \citep{papamakarios2016fast}. Moreover, this method does not produce a full posterior over the parameter but merely yields point estimates that can be used to approximate a posterior. Note that this posterior is then conditioned on an $\epsilon$-ball $\mid\mid x-x_0 \mid\mid < \epsilon$ around the observation rather than the actual observation $x_0$.\\
With Sampling ABC \citep{marjoram2003markov} and Sequential ABC \citep{beaumont2009adaptive,bonassi2015sequential} improvements over rejection ABC have been proposed. While these methods produce samples more efficiently, they suffer from the latter problem as well, as they only produce point estimates for parameters that produce something in $\epsilon$-range of $x_0$.

 



\section*{Neural Approach}
\begin{figure}
	\centering
	\includegraphics[width=.9\linewidth]{figures/sbi0.pdf}
	\caption{Given samples by the simulator, Multilayer perceptrons (MLP) are trained to parameterize a distribution over parameters generating the sample. A training signal is created by sampling from this distribution and comparing the sample to the actual parameters which are known.}
	\label{fig:sbiloop}
\end{figure} 
\citet{papamakarios2016fast} build on recent advances in deep learning and propose to learn a posterior over parameters directly from samples produced by a simulator. They parameterize a Gaussian Mixture Model (GMM) with a Bayesian Neural Network (BNN) with parameters $\phi = \mathcal{N}(\phi_m, exp^{\frac{1}{2}\phi_S})$ with mean $m$ and Covariance $S$. They perform $n$ simulations and store pairs of observations $x_i$ and corresponding parameters $\theta_i$, sampled from a proposal prior $\tilde{p}(\theta)$ to obtain the  training set $\lbrace(x_i,\theta_i)\rbrace_{i \in n}$. 
%The BNN $\phi$ is trained to predict a GMM
%\begin{align}
%	q_{\phi}(\theta\mid x) = \sum_k \alpha_k \mathcal{N}(\theta\mid m_k, S_k) = \sum_k \phi_1(x)_k \mathcal{N}(\theta\mid \phi_2(x)_k, diag(\phi_3(x))_k)
%\end{align}
%, where $k$ is the number of components, $\alpha$ is the mixing coefficient, $m$ the mean and $S$ the covariance matrix of a Gaussian, and $\phi_{\lbrace 1,2,3 \rbrace}$ are distinct (but not necessarily mutually exclusive) subsets of $\phi$.\\
To find a suiting $\phi$, $x_{0,...,n}$ are passed to it. Each respective output is used to parameterize a GMM $q_{\phi}(\theta\mid x) = \sum_k \alpha_k \mathcal{N}(\theta\mid m_k, S_k)$ with $k$ components, mixing coefficient $\alpha_k$, mean $m_k$, and covariance $S_k$. \\
An expectation $\frac{1}{N} \sum_n\mathbb{E} \left[ log\;q_{\phi}(\theta \mid x)\right]$ is estimated empirically through sampling. An regularization term $\frac{1}{N}\mathit{D}_{KL}(q^t(\phi) \mid\mid p(\phi))$, where $p(\phi)$ is a isotropic, zero-centered prior over weights is computed analytically. These terms form a loss $\mathcal{L}$ which returns a scalar value that can be backpropagated so that the first term is maximized and the latter minimized.\\
This completes an 'inner' training loop. \citet{papamakarios2016fast} further propose an 'outer' training loop, where once $\phi$ is fitted to $n$ observations, $\frac{p(\theta)}{\tilde{p}(\theta)}q(\theta \mid  x=x_0)$ replaces the proposal prior for a specific observation of interest. This, however, requires $\tilde{p}(\theta)$ to be of a form so that the importance weights $\frac{p(\theta)}{\tilde{p}(\theta)}$ can be computed analytically.




%
%\begin{algorithm}[H]
%	\caption{Training loop proposed by \citet{papamakarios2016fast}.}
%	%	\tcp{Initial proposal prior}
%	$\tilde{p}(\theta) \leftarrow p(\theta)$\\
%	%	\tcp{Create training set}
%	\Repeat{$\tilde{p}(\theta)$ has converged}{
%		\For{$n=1..N$}{
%			sample $\theta_n \sim \tilde{p}(\theta)$ \\
%			sample $x_n \sim p(x\mid \theta_n)$ \\
%		}
%		train $q_{\phi}(\theta\mid x)$ on $\lbrace x_n, \theta_n \rbrace$\\
%		%		\color{orange}$\hat{p}(\theta\mid x=x_0) \leftarrow \frac{p(\theta)}{\tilde{p}(c)}q_{\phi}(\theta\mid  x)$
%		$\tilde{p}(\theta) \leftarrow \frac{p(\theta)}{\tilde{p}(\theta)}q_{\phi}(\theta\mid x)$}
%	\label{alg:prior}
%\end{algorithm}


\section*{Application in Neuroscience}
\citet{lueckmann2017flexible} propose further enhancements to \citet{papamakarios2016fast}'s method. They apply SBI to forward models used in neuro-science, such as the Hodgkin-Huxley model \cite{hodgkin1952quantitative}. Simulators in this field frequently produce nonsensical observations \citep{lueckmann2017flexible}. To alleviate this, \citet{lueckmann2017flexible} additionally train a classifier that learns to detect parameter sets that will produce such 'bad' simulations, which are then discarded. They state that finding useful summary statistics of the often high-dimensional data is challenging. By using a  recurrent neural network to extract features from observations, they find an informative, learned summary statistic. Moreover, \citet{lueckmann2017flexible} formulate a loss such that it includes the importance weighting. This allows the use of more complex proposal priors, as they don't need to be computed analytically in their method. In the regularization term of their loss, they replace the isotropic, zero-centered Gaussian as prior in the regularization term through the posterior over weights from previous round to implicitly store information.\\
\citet{lueckmann2017flexible} evaluate their method for different models and find that it reliably finds matching parameter settings for synthetic data. On in-vitro experiments they find parameter settings that match empirical data accurately.







\section*{Conclusion}
Simulators are an important tool of reasarch scientiest across domains. 
\citet{papamakarios2016fast} and \citet{lueckmann2017flexible} leverage recent advances in deep learning and variational inference to efficiently perform simulation-based inference in challenging settings. An afterthought of our summary is that SBI methods can be applied in different settings but may require adaptions to suit the task.


%
% \citet{papamakarios2016fast} build on recent advances in deep learning and propose a flexible and powerful SBI framework. \citet{lueckmann2017flexible} apply their method to a neuro-science setting and alleviate some encountered shortcomings by introducing further enhancements.




\bibliography{references}
\end{document}