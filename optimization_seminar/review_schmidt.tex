\newcommand{\COURSE}{}
\newcommand{\STUDENT}{Review of R. Schmidt - Learned Optimizers: A review of recent advances}

\documentclass[a4paper]{scrartcl}

%\newcommand{\setlabel}[1]{\edef\@currentlabel{#1}\label}
\usepackage[utf8]{inputenc}
\usepackage[ngerman]{babel}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{fancyhdr}
\usepackage{color}
\usepackage{natbib}
\usepackage{graphicx}
\usepackage{lastpage}
\usepackage{listings}
\usepackage{tikz}
\usepackage{pdflscape}
\usepackage{subfigure}
\usepackage{float}
\usepackage{polynom}
\usepackage{hyperref}
\usepackage{tabularx}
\usepackage{forloop}
\usepackage{geometry}
\usepackage{listings}
\usepackage{fancybox}
\usepackage{tikz}
\usepackage{algpseudocode,algorithm,algorithmicx}

%Definiere Let-Command für algorithmen
\newcommand*\Let[2]{\State #1 $\gets$ #2}

\input kvmacros

%Größe der Ränder setzen
\geometry{a4paper,left=3cm, right=3cm, top=3cm, bottom=3cm}


%\bibliographystyle{apalike}	% lengthly
%Kopf- und Fußzeile
\pagestyle {fancy}
\fancyhead[L]{\STUDENT}
\fancyhead[C]{\COURSE}
%\fancyhead[R]{\today}

\fancyfoot[L]{}
\fancyfoot[C]{}
\fancyfoot[R]{Page \thepage /\pageref*{LastPage}}



\begin{document}	
\section*{Summary and Contributions}
The authors give an overview and review of the emerging field of learned optimizers. Learned optimizers would alleviate the need for handcrafted optimization algorithms and costly hyperparameter tuning.\\
The authors give an introduction to the supervised deep learning setting. They explain the task of optimization in such a setting and give formal context. Popular, \textit{traditional} gradient-based methods are described in detail.\\
The authors then continue by giving an elaborate introduction to the notion of learned optimizers. They also support their formal explanation with figures to help the reader build an intuition. \\
With a formal background established, different approaches to tackle the challenge of learning optimizers are introduced. Special emphasis is laid on a strain of work by Metz et al. which is discussed further. The results of this work are described in detail and are critically evaluated.

\section*{Strengths}
The reviewer positively notes that
\begin{itemize}
	\item the \textit{Fundamentals} section gives a detailed formal background,
	\item the written language is precise and free of errors,
	\item the relevance of the topic is stated clearly,
	\item visuals are used well,
	\item the idea of learned optimizers is explained in detail,
	\item literature is well selected
	\item weaknesses of the discussed work are assessed critically,
	\item and specific problems are pointed out.
\end{itemize}


\section*{Weaknesses}
The reviewer negatively notes that
\begin{itemize}
	\item the \textit{No-free-lunch-theorem} could use more context,
	\item and that some commas were wrong.
\end{itemize}




\section*{Correctness}
While the reviewer is not particularly familiar with the relevant literature, all references appear to be cited properly. The reviewer could not find any false formulations or equations.

\section*{Clarity}
The work is easy to follow. The structure is well composed. Language is precise and detailed. Equations and text support each other. Visuals provide further intuition where needed. Overall, the work is clear and precise.

\section*{Further Comments}
The work provides a good overview of the emerging field of learned optimizers. While clear motivation is given, all described work is discussed critically, making it a very good review.


\section*{Rating and Confidence}
\begin{itemize}
	\item Overall Score: 9.9
	\item Confidence: 7.5
\end{itemize}




	
\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End: